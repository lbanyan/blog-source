---
title: 机器学习推荐系统增量推荐优化
date: 2017-07-09 10:36
tag:
    - 机器学习
    - 增量推荐
---

### 背景
平台每次筛选300个在线主播进行打分排序。将这300个主播分三批，每批100个，交给三个机器学习的进程打分，目前该进程完成每批打分需要120ms左右。为了降低机器学习进程负载，考虑采用增量方式打分推荐。
1. 主播会下线。
2. 每次筛选出的300个主播中有部分是重复的。
3. 用于机器学习计算所需的用户特征2分钟更新一次。
4. 不同的用户推荐不同的主播，不同的用户的主播的打分不同，即此为个性化推荐。

<!--more-->

### 方案一
为了提高性能，弱化掉上述第3点，即弱化平台的部分实时性。将每次推荐的主播打分缓存起来，下次推荐时，新选出的300个主播，只对没有打分的主播打分。此缓存时效2小时。

#### 事先准备
以下验证均验证峰值时段，因为平台只要可以扛得住峰值时段，其他时段就没什么问题。
- 需先确认2小时内用户再次请求比例
如果为0，则此缓存没有意义。经统计，大致15%左右的用户会产生再次请求。
- 需先确认所需缓存的内存容量
如果所需缓存大小上百G，在不使用缓存集群的情况下，此缓存功能无法实现。我的公共缓存使用的是Redis，180万用户缓存大小约为21G。此处部分数据涉嫌公司秘密，不便详解。经验证，我的那台Redis机器内存足够。
- 验证峰值情况下Redis性能
经验证，恶劣情况下，读写一条数据，均在1.6ms左右。可以满足业务要求。注意，需要清理掉这台缓存服务器上其他不相干的服务，以防止其他服务进程占用内存导致异常。
- 使用redis.setex设置该缓存，缓存时长2小时。

#### 效果
采用此方案，长期观察，效果不佳，命中率基本维持在2%。

### 方案二
方案一并没有起到很好的优化效果，原因是平台有60%用户每天只访问一次，这一部分是无法命中缓存的。即使剩下的40%用户会出现第二次第三次访问，但是在此期间在线主播已经发生了变化，而且用户的第二次访问有可能在2个小时以后，自然也无法命中缓存。
**优化应该抓大头**。是否可以优化这第一次请求呢，即事先离线算好这批用户的推荐主播并缓存。在该用户第一次请求时，从缓存中取在线的主播来推荐。凌晨由于访问量很少，很适合用这段时间来计算。
如果计算全平台所有用户和所有主播的分值关系，一是所需存储巨大，而是无法计算完。
有以下问题需要解决：
- 缓存的用户应该是第二天尽可能出现的用户
- 缓存的用户对应的主播也应是第二天尽可能会在线且会推荐给该用户的主播
即这是一种预测，预测第二天这个用户会出现，并且预测那时候会给他推荐哪些在线主播，把这些主播提前打分好，便可以提高用户第一次访问时的缓存命中率。

#### 做法
- 记录七天内，每个用户的访问次数
- 记录七天内，给该用户推荐过的每一个主播及推荐过该主播的次数
- 每日凌晨对访问次数>x的用户中推荐过的主播次数>y的主播进行打分
- 用户第一次访问时，平台筛选出300个在线主播，对未命中缓存的主播打分，然后和命中缓存的主播合并，推荐给该用户，同时更新缓存中用户访问次数和推荐的主播次数
- 用户第二次及之后访问时，不在使用缓存

为什么用户第二次之后访问不能再使用缓存，是因为这些用户有了第一次访问行为，用户特征可能已经发生变化了，再使用缓存，会对主播推荐列表顺序造成较大影响。用户第一次之所以可以使用缓存，也正是这时用户还没有当日的行为，即用户特征没变化。

#### 效果
随着平台运行时间的增长，平台学习到的用户和主播的上述关系越来越准确，缓存命中率也越来越高。刚开始时的缓存命中只有2%，两天后缓存命中率达到了20%，还在不断增长。

### 方案三
使用增量请求的方式

#### 做法
每次只给用户推荐100个在线主播，客户端每次都会记录曝光给该用户了哪些主播，用户再次请求，会告诉服务端哪些主播已经曝光给该用户，服务端据此，将这些主播排除后，再推荐100个在线主播给该用户，依次循环。客户端对已曝光过的主播有缓存过期时间。

#### 效果
该做法可以无限量给用户推荐在线主播。但推荐效果可能会下降，原因是用户一般一天只看一次，且只看前四五十个主播。潜在主播（机器学习根据用户行为学习到并不能直接通过用户行为直接推出的主播）会下降较多。对用户观看引导不利。但实际效果还是需要根据数据来说话。

### 调试中的问题
- 单机性能很高，每批处理速度40ms，多机后，每批处理速度增加至60ms
原因：刚开始以为可能负载均衡器的问题，但并不是。实际是，新增机器后，立马测试，HTTP异步连接池大部分连接还都是新建的，自然慢了。要等一段预热的时间测试才好。
